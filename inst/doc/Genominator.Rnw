%\VignetteIndexEntry{The Genominator User Guide}
%\VignetteDepends{Genominator}
%\VignettePackage{Genominator}
\documentclass[letterpaper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%% Standard Packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{fancyvrb}
\usepackage{caption}
\usepackage{comment}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{color}

%%%%%%%%%%%%%%%%%%%%%%%% Adapted from Sweave %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\DefineVerbatimEnvironment{Rcode}{Verbatim}{fontshape=sl, frame=single, 
  framesep=2mm, fontsize=\small, baselinestretch=.5}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%% My macros (which of course are borrowed from a million ... %%
\def\argmax{\operatornamewithlimits{arg\,max}}
\def\argmin{\operatornamewithlimits{arg\,min}}

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textit{#1}}}
\newcommand{\myurl}[1]{\href{http://#1}{\textcolor{red}{\texttt{#1}}}}
\newcommand{\myem}[1]{\structure{#1}}

%%%%%%%%%%%%%%%%%%%%%%%% Page and Document Setup %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\addtolength{\oddsidemargin}{-0.875in}
\addtolength{\topmargin}{-0.875in}
\addtolength{\textwidth}{1.75in}
\addtolength{\textheight}{1.75in}

\captionsetup{margin=15pt,font=small,labelfont=bf}

\renewcommand{\topfraction}{0.9}        % max fraction of floats at top
\renewcommand{\bottomfraction}{0.8}     % max fraction of floats at bottom

% Parameters for TEXT pages (not float pages):
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}             % 2 may work better
\setcounter{dbltopnumber}{2}            % for 2-column pages
\renewcommand{\dbltopfraction}{0.9}     % fit big float above 2-col. text
\renewcommand{\textfraction}{0.07}      % allow minimal text w. figs

% Parameters for FLOAT pages (not text pages):
\renewcommand{\floatpagefraction}{0.7}          % require fuller float pages

% N.B.: floatpagefraction MUST be less than topfraction !!
\renewcommand{\dblfloatpagefraction}{0.7}       % require fuller float pages

%%%%%%%%%%%%%%%%%%%%%%% options for sweave %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\SweaveOpts{prefix.string=plots/genominator}

%%%%%%%%%%%%%%%%%%%%%% headers and footers %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{fancy} 
\renewcommand{\footrulewidth}{\headrulewidth}

%%%%%%%%%%%%%%%%%%%%%%%%% bibliography  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{plainnat}

%%%%%%%%%%%%%%%%%%%%%%% opening %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Genominator}
\author{James Bullard, Kasper Daniel Hansen}
\begin{document}
\maketitle

<<initialize,echo=FALSE,results=hide>>=
options(width = 70)
@ 

<<debug>>=
## -- For Debugging / Timing 
## require(RSQLite)
## source("../../R/Genominator.R")
## source("../../R/importAndManage.R")
## source("../../R/plotRegion.R")
## source("../../R/coverage.R")
@ 

\section{Introduction}

The \Rpackage{Genominator} provides an interface to storing and
retrieving genomic data, together with some additional functionality
aimed at high-throughput sequence data.  The intent is that retrieval
and summarization will be fast enough to enable online experimentation
with the data.

We have used to package to analyze tiling arrays and (perhaps more
appropriate) RNA-Seq data consisting of more than 400 million reads.
The canonical use case at the core of the package is summarizing the
data over a large number of genomic regions, for example counting the
number of reads that lands in all annotated exons in human.

Data is stored in a SQLite database, and as such the package makes it
possible to work with very large datasets in limited memory.  However,
working with SQLite databases is limited by I/O (disk speed), and
substantial performance gains are possible by using a fast disk.

\section{Data Model}

\subsection{Experimental Data}

The \Rpackage{Genominator} package provides a streamlined interface to
genomic data. The main goal of the package is to provide fast methods
for summarizing regions of interest oriented along the genome. The
package utilizes \Rpackage{RSQLite} to store the data corresponding to
an experiment. This data model is:

\begin{verbatim}
chr INTEGER, strand INTEGER (-1,0,1), location INTEGER, [name NUMERIC]*
\end{verbatim}

Specifically it means that each data unit has an associated
\texttt{chr} (chromosome coded as an integer), \texttt{strand}
(one of -1, 0, or 1 representing reverse strand, no strand
information, and forward strand respectively) as well as a
\texttt{location}.  We also allow an unlimited number of additional
numeric variables. The requirement that the additional variables be
numeric is purely an optimization. 

Examples are
\begin{verbatim}
chr INTEGER, strand INTEGER (-1,0,1), location INTEGER, counts INTEGER
chr INTEGER, strand INTEGER (-1,0,1), location INTEGER, chip_1 REAL, chip_2 REAL
\end{verbatim}

\subsection{Annotation}

The goal in this setup is often to summarize experimental data with
respect to annotation. Unlike experimental data, which is stored in
an SQLite database, we represent annotation as an R data.frame with the
following columns:

\begin{verbatim}
chr integer, strand integer (-1L,0L,1L), start integer, end integer, [name class]*
\end{verbatim}

As in the experimental data representation, strand information is
encoded as -1 for Reverse/Minus Strand, 0 for No Strand Information
Available/Relevant, and 1 for Forward/Plus Strand.

A common example is
\begin{verbatim}
chr integer, strand integer (-1L,0L,1L), start integer, end integer, feature factor
\end{verbatim}

\section{Interface}

\subsection{Creating Experimental Data}

In this setting there are often things we want to do to various
classes of annotation. We are going to walk through a very simple
example using simulated experimental data to present the pipeline.
This example uses a verbose setting of TRUE to illustrate activities
performed in the SQLite databases.

<<createExpData>>=
library(Genominator)

options(verbose = TRUE) # to be used by Genominator functions.

set.seed(123)

N <- 100000L # the number of observations. 
K <- 100L    # the number of annotation regions, not less than 10

df <- data.frame(chr = sample(1:16, size = N, replace = TRUE),
                 location = sample(1:1000, size = N, replace = TRUE),
                 strand = sample(c(1L,-1L), size = N, replace = TRUE))

head(df)
eDataRaw <- importToExpData(df, filename = "my.db", tablename = "ex_tbl", overwrite = TRUE)
eDataRaw

eData <- aggregateExpData(eDataRaw, tablename = "counts_tbl", deleteOriginal = FALSE, 
                          overwrite = TRUE)
eData
@ 

Functions such as \Rfunction{importToExpData} and
\Rfunction{aggregateExpData} instantiate ExpData objects that, for
all practical purposes, may be considered to point to a specific
table in an SQLite database. These functions have a number of
database bookkeeping arguments that regulate which database to use
and what database tables to create and delete. For example, the
overwrite argument indicates whether the database table referred to
in the tablename argument should be overwritten, and the deleteOriginal
argument to \Rfunction{aggregateExpData} indicates whether the database
table created in the \Rfunction{importToExpData} step should be deleted
from the database.

%% this could use some clarification
Also, you can use the ``original'' table name. Note that the display
of ``eDataRaw'' in this instance is broken as the underlying database
has been changed and some properties of the object are set at
instantiation. In general, it is advisable to carry out the steps
involved in building a database and then in separate scripts carry out
various analyses.
<<>>=
eData <- aggregateExpData(eDataRaw)
eData
@ 

Each ExpData object has a mode that indicates whether the database is
in read or write (which also implies read) mode. The ``eDataRaw'' and
``eData'' objects created above had a 'write' mode. To prevent
unwanted modifications to the database, we will instantiate an object
in 'read' only mode. 
<<>>=
eData <- ExpData("my.db", tablename = "ex_tbl")
eData
@ 

\subsection{Summarizing Experimental Data}

We can use the function \Rfunction{summarizeExpData} to summarize
ExpData objects to get an idea of what we have. The call to generate
the total number of counts in column ``counts'' is
<<>>=
ss <- summarizeExpData(eData, what = "counts")
ss
@ 

We can customize the summary by specifying the name of any SQLite
function (\myurl{www.sqlite.org/lang\_aggfunc.html}) in the fxs
argument
<<>>=
summarizeExpData(eData, what = "counts", fxs = c("MIN", "MAX"))
@ 

\subsection{Selecting Regions in Experimental Data}

We can access genomic data using the function \Rfunction{getRegion}.
<<>>=
reg <- getRegion(eData, chr = 1L, strand = 1L)
head(reg)
baseCounts <- table(df[df$chr == 1L & df$strand == 1L, "location"])
head(baseCounts)
@ 

This function optionally takes a number of arguments. 
<<>>=
x <- getRegion(eData, chr = 2L, start = 100L, end = 105L, strand = -1L)
head(x)
@ 

\subsection{Creating Annotation}

Now we need to create a suitable annotation object. This can be
simulated using the following code: 
<<>>=
annoData <- data.frame(chr = sample(1:16, size = K, replace = TRUE),
                       strand = sample(c(1L, -1L), size = K, replace = TRUE),
                       start = (st <- sample(1:1000, size = K, replace = TRUE)),
                       end = st + rpois(K, 75),
                       feature = c("gene", "intergenic")[sample(1:2, size = K, replace = TRUE)])
rownames(annoData) <- paste("elt", 1:K, sep = ".")
head(annoData)
@ 
Note that annoData needs to have distinct row names. This is done
to maintain the link between annotation and returned data structures
from the \Rpackage{Genominator} API. 

\subsection{Using Annotation with Experimental Data}

Now that we have our experimental data and our annotation data structures,
we can
\begin{itemize}
\item Summarize regions (means, lengths, sums, etc)
\item Fit models on each region
\item Perform operations over classes of regions (genes, intergenic
  regions, ncRNAs)
\end{itemize}

First, we demonstrate how we can summarize over regions of
interest. Here we are going to compute the SUM and COUNT of each
region. This is telling us the total number of sequencing reads at
each location and the number of unique locations that were read.
<<>>=
head(summarizeByAnnotation(eData, annoData, what = "counts", fxs = c("SUM", "TOTAL"),
                           bindAnno = TRUE))
@ 

<<>>=
head(summarizeByAnnotation(eData, annoData, what = "counts", fxs = c("SUM"),
                           bindAnno = TRUE,  preserveColnames = TRUE))
@ 

%% this could use some clarification
In this case, an important distinction between the functions ``SUM''
and ``TOTAL'' is not evident. This distinction is that ``SUM'' will
return NA if any row in the dataset contains NA. Often we will add NA
(or NULL in the database) when we join two datasets.

We can produce summarizes by category using the splitBy argument.
<<>>=
res <- summarizeByAnnotation(eData, annoData, what = "counts", fxs = c("SUM", "COUNT"), 
                             splitBy = "feature")
class(res)
lapply(res, head)
@ 

Finally, we might want to join the relevant annotation to the summaries
using the bindAnno argument.
<<>>=
res <- summarizeByAnnotation(eData, annoData, what = "counts", fxs = c("SUM", "COUNT"), 
                             splitBy = "feature", bindAnno = TRUE)
lapply(res, head)
@ 

%% this could use some clarification
Unfortunately, the \Rfunction{summarizeByAnnotation} function only
supports a small set of SQL functions and a more general interface
is provided. The cost is of course performance. 

A common task with data that have been split up into regions of
interest will be to fit some kind of model to the data within those
regions. Due to the size of these data sets it is generally advisable
to save some copy of the ``mapped'' data. 
<<>>=
dim(annoData[annoData$feature %in% "gene", ])
a <- splitByAnnotation(eData, annoData[annoData$feature %in% "gene", ])
class(a)
length(a)
names(a)[1:10]
@ 

%% this could use some clarification
It is important to understand what \Rfunction{splitByAnnotation}
returns and why the length of object "a" above is not 10 as you might
expect. When the region is empty that region is dropped. The names of
the resulting list will correspond the names of the annotation object
and can be used to subselect the annotation object. Additionally, the
\Rfunction{applyMapped} can be used to map over the resulting list
with the annotation.

Ignoring strand information could be:
<<>>=
b <- splitByAnnotation(eData, annoData, ignoreStrand = TRUE)
class(b)
length(b)
names(b)[1:10]
@ 

Now we wish to compute a trivial function over the counts, such as a
quantile.
<<>>=
sapply(a, function(x) { quantile(x[,"counts"], .9) })[1:10]
@ 

Often we wish to do the former, but include some information from the
annotation. In this case we can use the function mentioned above to
coordinately walk over both of the annotation and the results of
mapping in lock-step.

This function ensures that you are applying the right bit of
annotation to the correct chunk of data.
<<>>=
applyMapped(a, annoData, FUN = function(region, anno) { 
    counts <- region[,"counts"]
    table(counts)
})[1:10]
@ 

What we see is that some of our regions are not present. This is a
byproduct of the fact that some of our regions have no data within
their bounds. 

When our data sets are large it is often more convenient to only
select a subset of the data to use, this can often be significantly
faster. 
<<>>=
sapply(splitByAnnotation(eData, annoData, what = "counts"), median)[1:10]
@ 

Often we wish to ``fill'' in regions which we are missing. In the case
of a coding sequence there may be bases that have no reads which will
not appear in our resulting object. We can ``expand'' a region to
include these bases filling in 0 reads for them. There are different
ways to do this expansion. For convenience, things are stratified by
strand, therefore expansion will produce a list-of-lists where each
sub-list has possibly two elements corresponding to each strand. If
the original annotation query is stranded, then expansion will produce
a list where each sublist only has one element. Finally, we provide a
feature to collapse across strand for the common case where one wishes
to combine reads occurring on either strand within the region. In this
case the return value is a list where each element is an expanded
matrix representing the reads which occurred on either strand. 

<<>>=
## This returns a list-of-lists 
x1 <- splitByAnnotation(eData, annoData, expand = TRUE, ignoreStrand = TRUE)
names(x1[[1]])

## this returns a list-of-lists, however they are of length 1
x2 <- splitByAnnotation(eData, annoData, expand = TRUE)
names(x2[[1]])

## this returns a list where we have combined the two sublists
x3 <- splitByAnnotation(eData, annoData, expand = TRUE, addOverStrand = TRUE)
head(x3[[1]])
@ 

Finally, we often want to compute summaries of higher level entities,
such as genes, pseudogenes, and intergenic regions. We can do these
types of operations using the \Rfunction{mergeWithAnnotation} convenience
function.
<<>>=
mergeWithAnnotation(eData, annoData)[1:3,]
@ 

There are a number of parameters that can make this more natural. 
<<fig=TRUE>>=
par(mfrow=c(1,2))
x <- lapply(mergeWithAnnotation(eData, annoData, splitBy = "feature", what = "counts"), 
            function(x) { 
                plot(density(x)) 
            })
@ 

\section{Managing Data}
\subsection{Merging}
Often we want to incorporate other datasets that share many of the
same features. It is natural to store a number of experimental replicates
in columns of a table. However, it is often the case that we receive the
data in chunks over time, and that merging new values with old values is
not trivial. For this reason we provide a \Rfunction{mergeExpData} to bind
two tables together. 

<<>>=
N <- 100000
dfNew <- data.frame(chr = sample(1:16, size = N, replace = TRUE),
                    location = sample(1:1000, size = N, replace = TRUE),
                    strand = sample(c(1L,-1L), size = N, replace = TRUE))

@ 

One thing we could do is: 
<<eval=FALSE>>=
merged <- merge(df, dfNew, by = c("chr", "location", "strand"), all = T)
mData <- importToExpData(merged, filename = "my.db", tablename = "hand_merged",
                         overwrite = TRUE)
@ 

However, we might have some issues with memory for really big things
and the merge function is typically *much* slower in R than in the
database. Also, and very commonly, we have data from a previous
experiment and we wish to augment the dataset with a new run. So in
this case we can join the datasets in the following way. In this
manner we can join ``lanes'' from a set of sequencing runs, or can
join microarray experiments.

<<>>=
eData1 <- aggregateExpData(importToExpData(dfNew, filename = "my.db", tablename = "ex1", 
                                           overwrite = TRUE))
eData2 <- aggregateExpData(importToExpData(df, filename = "my.db", tablename = "ex2", 
                                           overwrite = TRUE))

ed <- joinExpData(list(eData1, eData2), fields = 
                  list(ex1 = c(counts = "counts_1"), ex2 = c(counts = "counts_2")), 
                  tablename = "allcounts")

summarizeExpData(ed, fxs = c("sum", "total", "avg"))
@ 


\subsection{Collapsing}
Another common operation that we often want to do is to collapse data
according to groups. A good example of this is when we have multiple
lanes and we want to aggregate the lanes in the database to facilitate
future downstream computations.
<<>>=
head(collapseExpData(ed, tablename = "collapsed", collapse = "weighted.avg", overwrite = TRUE))
head(collapseExpData(ed, tablename = "collapsed", collapse = "avg", overwrite = TRUE))
head(collapseExpData(ed, tablename = "collapsed", collapse = "sum", overwrite = TRUE))
@ 

\section{Coverage}

In the case of short read sequencing data the Genominator package
offers a number of specific functionality which is often useful. The
\Rfunction{computeCoverage} function can be used to assess the
sequencing depth. 
<<fig=TRUE>>=
coverage <- computeCoverage(eData, annoData, effort = seq(100, 1000, by = 5), 
                            cutoff = function(e, anno, group) e > 1)
plot(coverage, draw.legend = FALSE)
@ 

\section{Statistical Functions: Goodness of Fit}

You can conduct a goodness of fit analysis to the Poisson model across
lanes using the following function. 

<<fig=TRUE>>=
plot(regionGoodnessOfFit(ed, annoData))
@ 

<<fig=TRUE>>=
plot(regionGoodnessOfFit(as.data.frame(matrix(rpois(1000, 100), ncol = 10)),
                         groups = rep(c("A", "B"), 5), denominator = rep(1, 10)))
@ 



\end{document}
